{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Effnet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JL4vY78VnHyk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Google Colab 연결\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seed 고정\n",
        "import torch\n",
        "import random\n",
        "\n",
        "def seed_everything(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "seed_everything(2022)"
      ],
      "metadata": {
        "id": "9FF9B6UOnMuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/AI_individual/Dacon_hand_gesture/data/train.csv') # 2335 rows 34 columns\n",
        "test = pd.read_csv('/content/drive/MyDrive/AI_individual/Dacon_hand_gesture/data/test.csv')   # 9343 rows 33 columns\n",
        "submission = pd.read_csv('/content/drive/MyDrive/AI_individual/Dacon_hand_gesture/data/sample_submission.csv')"
      ],
      "metadata": {
        "id": "8f1OAWmnnasz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_post(x_in):\n",
        "    x = LeakyReLU()(x_in)\n",
        "    x = BatchNormalization()(x)\n",
        "    return x\n",
        "\n",
        "def get_block(x_in, ch_in, ch_out):\n",
        "    x = Conv2D(ch_in,\n",
        "               kernel_size=(1, 1),\n",
        "               padding='same',\n",
        "               use_bias=False)(x_in)\n",
        "    x = get_post(x)\n",
        "\n",
        "    x = DepthwiseConv2D(kernel_size=(1, 3), padding='same', use_bias=False)(x)\n",
        "    x = get_post(x)\n",
        "    x = MaxPool2D(pool_size=(2, 1),\n",
        "                  strides=(2, 1))(x) # Separable pooling\n",
        "\n",
        "    x = DepthwiseConv2D(kernel_size=(3, 1),\n",
        "                        padding='same',\n",
        "                        use_bias=False)(x)\n",
        "    x = get_post(x)\n",
        "\n",
        "    x = Conv2D(ch_out,\n",
        "               kernel_size=(2, 1),\n",
        "               strides=(1, 2),\n",
        "               padding='same',\n",
        "               use_bias=False)(x)\n",
        "    x = get_post(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def Effnet(input_shape, nb_classes, include_top=True, weights=None):\n",
        "    x_in = Input(shape=input_shape)\n",
        "\n",
        "    x = get_block(x_in, 32, 64)\n",
        "    x = get_block(x, 64, 128)\n",
        "    x = get_block(x, 128, 256)\n",
        "\n",
        "    if include_top:\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(nb_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=x_in, outputs=x)\n",
        "\n",
        "    if weights is not None:\n",
        "        model.load_weights(weights, by_name=True)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "SWJtqJOqnaqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.iloc[:, 1:-1]     # sensor_1 ~ sensor_32 / [2335, 32]\n",
        "target = test.iloc[:, 1:]   # sensor_1 ~ sensor_32 / [9343, 32]"
      ],
      "metadata": {
        "id": "Kx5f0l7bnaoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ohe = OneHotEncoder(sparse = False)\n",
        "y = ohe.fit_transform(train[['target']])    # [2335, 4]\n",
        "skf = StratifiedShuffleSplit(n_splits=10, train_size=0.9, test_size=0.1, random_state=2022)\n",
        "es = EarlyStopping(monitor = 'val_acc', patience = 10, mode = 'max', verbose = 1)"
      ],
      "metadata": {
        "id": "HN756DYhnamg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eff_acc = []\n",
        "eff_pred = np.zeros((target.shape[0], 4))   # [9343, 4]\n",
        "\n",
        "for i, (tr_idx, val_idx) in enumerate(skf.split(X, train.target)) :\n",
        "    print(f'{i + 1} Fold Training.....')\n",
        "    tr_x, tr_y = X[tr_idx], y[tr_idx]\n",
        "    val_x, val_y = X[val_idx], y[val_idx]\n",
        "    \n",
        "    ### Effnet 모델\n",
        "    input_shape = (8,8,1)   #(8,4,1)\n",
        "    eff = Effnet(input_shape=input_shape, nb_classes=4, include_top=True, weights=None)\n",
        "   \n",
        "\n",
        "    ### ModelCheckPoint Fold마다 갱신\n",
        "    mc = ModelCheckpoint(f'model_{i + 1}.h5', save_best_only = True, monitor = 'val_acc', mode = 'auto', verbose = 0)    # monitor 변경 / val_acc\n",
        "    \n",
        "    ### 모델 compile\n",
        "    eff.compile(optimizer = RMSprop(learning_rate = 0.0005), loss = 'categorical_crossentropy', metrics = ['acc'])            # optimizer 변경\n",
        "\n",
        "    eff.fit(tr_x, tr_y, validation_data = (val_x, val_y), epochs = 100, batch_size = 32, callbacks = [es, mc], verbose = 1)\n",
        "\n",
        "    ### 최고 성능 기록 모델 Load\n",
        "    best = load_model(f'model_{i + 1}.h5')\n",
        "    ### validation predict\n",
        "    val_pred = best.predict(val_x)\n",
        "    ### 확률값 중 최대값을 클래스로 매칭\n",
        "    val_cls = np.argmax(val_pred, axis = 1)\n",
        "    ### Fold별 정확도 산출\n",
        "    fold_eff_acc = accuracy_score(np.argmax(val_y, axis = 1), val_cls)\n",
        "    eff_acc.append(fold_eff_acc)\n",
        "    print(f'{i + 1} Fold ACC of CNN = {fold_eff_acc}\\n')\n",
        "\n",
        "    ### Fold별 test 데이터에 대한 예측값 생성 및 앙상블\n",
        "    fold_pred = best.predict(target) / skf.n_splits\n",
        "    # print(fold_pred.shape)\n",
        "    eff_pred += fold_pred"
      ],
      "metadata": {
        "id": "U10Y1XkQnakI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과 확인\n",
        "submission['target'] = np.argmax(eff_pred, axis = 1)\n",
        "print(np.argmax(eff_pred, axis = 1))\n",
        "print(np.mean(eff_acc))\n",
        "print(submission.target.value_counts())\n",
        "eff_pred"
      ],
      "metadata": {
        "id": "coOhUWoRnaiO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}